#### 数据降维

##### 特征选择API

```python
from sklearn.feature_selection import VarianceThreshold

var = VarianceThreshold(threshold=1.0)

data = var.fit_transform([[1,2,3],[4,5,6],[7,8,9]])

print(data)

```

##### PCA

* 是一种分析，简化数据集的技术

* 目的：是数据维数压缩，尽可能降低原始数据的纬度（复杂度），损失少量信息

* 可以削减回归分析或者聚类分析中特征的数量

```python
from sklearn.decomposition import PCA

pca = PCA(n_components=0.9)

data = pca.fit_transform([[1,2,3],[4,5,6],[7,8,9]])

print(data)

```

#### 数据特征预处理

##### 归一化API

```python
from sklearn.preprocessing import MinMaxScaler

mm = MinMaxScaler(feature_range(2, 3))

data = mm.fit_transform([[1,2,3],[4,5,6],[7,8,9]])

print(data)

```

##### 标准化公式

```python
x' = (x - mean) / 标准差
```

##### 方差

```python
var = (x1-mean)^2 + (x2-mean)^2 + ...... / 每个特征值的样本数
```

##### 标准差

```python
标准差 = 方差开根号
```

##### 特征化API

```python
from sklearn.preprocessing import StandardScaler

std = StandardScaler(feature_range(2, 3))

data = std.fit_transform([[1,2,3],[4,5,6],[7,8,9]])

print(data)

```

##### 缺失值API

```python
from sklearn.preprocessing import Imputer

im = Imputer(missing_values="NaN", strategy="mean", axis=0)

data = im.fit_transform([[1,2],[np.nan, 3],[7,8]])

print(data)

```

#### 特征文本抽取和中文问题

```python
import sklearn.feature_extraction.text import CountVectorizer

cv = CountVectorizer()

data = cv.fit_transform(["人生苦短","我爱python"])

print(cv.get_feature_names())

print(data.toarray())
```

##### jieba中文分词器

```python
pip install jieba
```

```python
import jieba

jieba.cut("我是一个程序员")
```

##### 字典特征数据抽取

```python
import sklearn.feature_extraction import DictVectorizer

dict = DictVectorizer()

data = dict.fit_transform([{"人生苦短"},{"我爱python"}])

print(cv.get_feature_names())

print(data.toarray())
```

#### tfidf分析问题

##### Tf 词的频率

##### idf 逆文档频率

```python
import sklearn.feature_extraction import TfidfVectorizer

tf = TfidfVectorizer()

data = tf.fit_transform([{"人生苦短"},{"我爱python"}])

print(tf.get_feature_names())

print(data.toarray())
```

#### 机器学习算法

##### 估计器

* 估计器是一类实现了算法的API

##### 用于分类的估计器

* sklearn.neighbors k近邻算法

* sklearn.naive_bayes 贝叶斯

* sklearn.linear_model.LogisticRegression 逻辑回归

* sklearn.tree 决策树和随机森林

##### 用于回归的估计器

* sklearn.linear_model.LinearRegression 线性回归

* sklearn.linear_model.Ridge 岭回归

##### 数据类型[离散型,连续型数据]

* 离散型在区间内不可分,连续型数据区间内可分

##### 机器学习算法分类[监督学习,非监督学习]

* 监督学习 [ k近邻算法, 贝叶斯, 决策树和随机森林, 逻辑回归, 神经网络, 线性回归, 岭回归]

* 非监督学习 [ k-means ]